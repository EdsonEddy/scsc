{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "066084ff",
   "metadata": {},
   "source": [
    "### Generation of CSV files for datasets\n",
    "This notebook is responsible for generating CSV files for the datasets used in the project. It creates a balanced dataset of file pairs, including both similar and dissimilar pairs, and saves it in a structured format for further analysis and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b23d496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules for file processing and comparison\n",
    "import os\n",
    "from scsc import Compare, simple_process_files\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Get the absolute path of the current working directory\n",
    "files_path = os.path.abspath(os.getcwd())\n",
    "# Navigate up one level to the parent directory\n",
    "parent_path = os.path.dirname(files_path)\n",
    "# Construct the path to the target directory containing Python files\n",
    "target_path = os.path.join(parent_path, \"datasets\", \"small\")\n",
    "# Load file names and contents from the target directory\n",
    "file_names, file_contents = simple_process_files(target_path)\n",
    "\n",
    "# Shuffle the file names and contents together to ensure random pairing\n",
    "arr_shuffled = list(zip(file_names, file_contents))\n",
    "random.shuffle(arr_shuffled)\n",
    "file_names, file_contents = zip(*arr_shuffled)\n",
    "\n",
    "\"\"\"\n",
    "    Maximum Limits and Thresholds for Pair Classification\n",
    "    -----------------------------------------------\n",
    "    To create a balanced dataset of similar and dissimilar pairs\n",
    "    we set maximum limits for positive and negative pairs\n",
    "\"\"\"\n",
    "MAX_POSITIVE_PAIRS = (\n",
    "    500  # Set a maximum limit for positive pairs to balance the dataset\n",
    ")\n",
    "MAX_NEGATIVE_PAIRS = (\n",
    "    500  # Set a maximum limit for negative pairs to balance the dataset\n",
    ")\n",
    "THRESHOLD = (\n",
    "    0.85  # Set a threshold for similarity score to classify pairs as similar or not\n",
    ")\n",
    "\n",
    "labels = []\n",
    "files = []\n",
    "\n",
    "scores_ted = []\n",
    "scores_mdiff = []\n",
    "scores_lf = []\n",
    "\n",
    "positive_cases = 0\n",
    "negative_cases = 0\n",
    "\n",
    "def fixed_file_name(file_name):\n",
    "    \"\"\"\n",
    "    Extract the base name of the file without extension for comparison.\n",
    "    This helps in identifying similar files that may have different extensions or paths.\n",
    "    \"\"\"\n",
    "    return os.path.splitext(os.path.basename(file_name))[0] + \".py\"\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "\n",
    "    for j in range(i + 1, len(file_names)):\n",
    "        score_ted = Compare(file_contents[i], file_contents[j], method=\"ted\")\n",
    "        score_mdiff = Compare(file_contents[i], file_contents[j], method=\"mdiff\")\n",
    "        score_lf = Compare(file_contents[i], file_contents[j], method=\"lf\")\n",
    "\n",
    "        if (\n",
    "            score_ted >= THRESHOLD\n",
    "            and score_mdiff >= THRESHOLD\n",
    "            and score_lf >= THRESHOLD\n",
    "            and positive_cases < MAX_POSITIVE_PAIRS\n",
    "        ):\n",
    "            labels.append(1)\n",
    "            files.append((fixed_file_name(file_names[i]), fixed_file_name(file_names[j])))\n",
    "            scores_ted.append(score_ted)\n",
    "            scores_mdiff.append(score_mdiff)\n",
    "            scores_lf.append(score_lf)\n",
    "            positive_cases += 1\n",
    "        elif negative_cases < MAX_NEGATIVE_PAIRS:\n",
    "            labels.append(0)\n",
    "            files.append((fixed_file_name(file_names[i]), fixed_file_name(file_names[j])))\n",
    "            scores_ted.append(score_ted)\n",
    "            scores_mdiff.append(score_mdiff)\n",
    "            scores_lf.append(score_lf)\n",
    "            negative_cases += 1\n",
    "\n",
    "\n",
    "data = {\n",
    "    'File_1': [pair[0] for pair in files],\n",
    "    'File_2': [pair[1] for pair in files],\n",
    "    'Label': labels\n",
    "}\n",
    "\n",
    "output_file = os.path.join(target_path, 'small_dataset.csv')\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "\n",
    "features_data = {\n",
    "    'File_1': [pair[0] for pair in files],\n",
    "    'File_2': [pair[1] for pair in files],\n",
    "    'TED': scores_ted,\n",
    "    'Myers Diff': scores_mdiff,\n",
    "    'Local Fingerprint': scores_lf,\n",
    "    'Labels': labels\n",
    "}\n",
    "\n",
    "features_df = pd.DataFrame(features_data)\n",
    "features_output_file = os.path.join(target_path, 'small_features_dataset.csv')\n",
    "features_df.to_csv(features_output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
